# üëã Bem-vindo ao Visage Track Project!

O Visage Track Project √© dedicado ao Reconhecimento de express√µes faciais em ambientes controlados, gerados proceduralmente utilizando t√©cnicas avan√ßadas de Geometria Anal√≠tica, √Ålgebra Linear e C√°lculo Num√©rico.

**Aluno:** J√°der Louis de Souza Gon√ßalves  
**Projeto:** Reconhecimento de express√µes faciais em ambientes controlados gerados proceduralmente.  
**Orientador:** Prof. Dr. Lucas Marques

![Perfil do Usu√°rio](https://github.com/visagetrack-project/.github/blob/687927c5ac1b96ad2807e33c2aa88ed99c9fa6e5/profile/unir%201.png)
# Funcionamento do Projeto

O projeto opera da seguinte forma: escolhemos utilizar um ambiente Unity controlado, uma vez que n√£o podemos usar imagens de pessoas reais para treinamento. Assim, criamos seres denominados "blobs" nesse ambiente controlado na Unity, utilizando a f√≥rmula blob para definir suas personalidades e tra√ßos caracter√≠sticos, os quais s√£o gerados aleatoriamente. Isso introduz um grande fator de imprevisibilidade ao projeto.

O projeto √© dividido em v√°rias partes: Web, Comunica√ß√£o, IA (Intelig√™ncia Artificial) e o Ambiente de Controle.

## WEB

Os reposit√≥rios web est√£o dispon√≠veis em:

- **Reposit√≥rio Web:** [vt-web](https://github.com/visagetrack-project/vt-web.git) - Ambiente web desenvolvido em Flutter, incluindo sistema de autentica√ß√£o e banco de dados Firebase.
- **API Prim√°ria:** [vt-api](https://github.com/visagetrack-project/vt-api.git) - Escrita em Go, essa API faz a comunica√ß√£o direta com a web e √© essencial para o funcionamento do projeto.

## Comunica√ß√£o

### API Prim√°ria

A API prim√°ria, cujo reposit√≥rio pode ser encontrado em [vt-api](https://github.com/visagetrack-project/vt-api.git), gerencia as requisi√ß√µes do servidor web e recebe dados processados da API secund√°ria.

### API Secund√°ria

Localizada em [vt-model](https://github.com/visagetrack-project/vt-model), esta API √© respons√°vel pelo processamento das imagens. O arquivo [api_communication.py](https://github.com/visagetrack-project/vt-model/blob/main/api_communication.py) √© utilizado para capturar, transformar os dados e envi√°-los para a API prim√°ria. Importante destacar que `main.py` n√£o chama esse arquivo diretamente; em vez disso, uma API terci√°ria gerencia essa comunica√ß√£o automaticamente, al√©m de gerar gr√°ficos.

### API Terci√°ria

Esta API, escrita em C# e hospedada em um reposit√≥rio privado, √© respons√°vel por gerar as imagens e envi√°-las para serem processadas pela IA. Ela tamb√©m recebe as imagens processadas de volta da API secund√°ria. Al√©m disso, essa API √© respons√°vel por criar um novo ambiente Unity a cada requisi√ß√£o atrav√©s do endpoint `/createNewAmbient{params1}/{params2}/{params3}`, preparando o cen√°rio para as opera√ß√µes das demais APIs.

## IA

### Sobre o EfficientDet-D0

O `EfficientDet-D0` √© uma arquitetura de Rede Neural Convolucional (CNN) desenvolvida para detec√ß√£o de objetos, fazendo parte da s√©rie EfficientDet introduzida pela Google Research. Essa fam√≠lia de modelos √© reconhecida por sua alta efici√™ncia, apresentando um equil√≠brio not√°vel entre a precis√£o e a velocidade de infer√™ncia. O `EfficientDet-D0`, sendo a vers√£o mais compacta e √°gil da s√©rie, √© ideal para aplica√ß√µes em ambientes com recursos computacionais restritos, mantendo, ainda assim, uma precis√£o de detec√ß√£o robusta.

### Processo Geral Incorporando o EfficientDet-D0

1. **Convers√£o do Modelo para TFLite**: Inicialmente, o modelo pr√©-treinado `EfficientDet-D0` √© convertido para TensorFlow Lite (TFLite), otimizando sua execu√ß√£o em dispositivos com limita√ß√µes de capacidade computacional.

2. **Detec√ß√£o de Objetos em Imagens**: Utilizando o modelo convertido, o script executa o `EfficientDet-D0` para identificar objetos em imagens. Atrav√©s da fun√ß√£o `tflite_detect_image`, a imagem √© processada, a infer√™ncia √© realizada e as caixas delimitadoras s√£o desenhadas ao redor dos objetos detectados.

3. **Gera√ß√£o de Arquivos XML e CSV**: Os dados das detec√ß√µes s√£o armazenados em arquivos XML, que cont√™m detalhes das detec√ß√µes por imagem, e em um arquivo CSV, que compila as classes identificadas.

### Funcionamento do EfficientDet-D0 no Script

- **Infer√™ncia Eficiente**: O script processa a imagem recebida da terceira API com o `EfficientDet-D0`, identificando a localiza√ß√£o e as classes dos objetos presentes. Atrav√©s de t√©cnicas avan√ßadas de detec√ß√£o e um backbone eficaz, o modelo consegue ser r√°pido e acurado, at√© mesmo em dispositivos com menor pot√™ncia computacional.

- **P√≥s-processamento e An√°lise**: Ap√≥s a infer√™ncia, o script realiza um p√≥s-processamento para extrair as coordenadas das caixas delimitadoras, as classes e as probabilidades dos objetos detectados. Essas informa√ß√µes s√£o utilizadas para ilustrar as caixas nas imagens, gerar arquivos XML para cada detec√ß√£o e compilar um resumo no arquivo CSV.

- **Comunica√ß√£o**: Subsequentemente, um vetor contendo 10 estados, com valores de 0 a 8 que representam as medi√ß√µes realizadas pela IA, √© recebido. Esses dados s√£o processados em [analysis.py](https://github.com/visagetrack-project/vt-model/blob/main/analysis.py) e enviados para a API prim√°ria.

### Aplica√ß√£o do EfficientDet-D0

Os resultados obtidos podem ser visualizados na seguinte imagem: ![blobs.jpeg](https://github.com/visagetrack-project/.github/blob/a0ad6ef25561d476ca5be027df0538b9d013afd8/profile/blobs.jpeg)


## Documenta√ß√£o do funcionamento dos 'Blobs'

Para entender o comportamento dos Blobs, √© essencial compreender a f√≥rmula do Gerador Linear Congruente (GLC), que √© a base de tudo isso.

![Documento Blob](https://github.com/visagetrack-project/.github/blob/687927c5ac1b96ad2807e33c2aa88ed99c9fa6e5/profile/WhatsApp%20Image%202024-02-12%20at%2016.09.49.jpeg)

Para entender o comportamento dos Blobs √© essencial entender a formula de GLC (Gerador Linear Congruente), que √© a base de tudo isso
Usando a formula para gerar n√∫meros aleat√≥rios:

$$
X_{n+1} = (aX_n + c) \mod m
$$

- Xn+1‚Äã representa o pr√≥ximo n√∫mero na sequ√™ncia,
- a √© o multiplicador,
- Xn‚Äã √© o n√∫mero atual ou a semente,
- c √© o incremento,
- m √© o m√≥dulo.


Logo definimos as caracter√≠sticas iniciais:

$$
\begin{align*}
\text{Sejam } & min = 0 \text{ e } max = 100. \\
\text{Para cada vari√°vel } & x \in \{ \text{laziness}, \text{commitment}, \text{interest} \}, \\
& x = X_{n+1} = (aX_n + c) \mod m(min,max).
\end{align*}
$$

$$
\begin{align*}
\text{taxaPraDiminuirEmLaziness} &= \frac{\text{commitment}}{2} + \left( \frac{\text{laziness}}{32 - \text{daysCount}} \right) \\\\
\text{commitment} &> 45 =  \\
x &= \left( \frac{5}{1 + \text{laziness}} \right) \cdot \left( \text{interest} \cdot \frac{\text{taxaPraDiminuirEmLaziness}}{100} \right),  \text{estado} = 1 \\ \\
\text{commitment} &< 45 =  \\
x &= \left( \frac{\text{laziness}}{10} \right) \cdot \left( \text{interest} \cdot \frac{\text{taxaPraDiminuirEmLaziness}}{1000} \right), \text{estado} = 0 \\\\
& x > 10,  x = 10 \\
& x < -10,  x = -10 
\end{align*}
$$

> [!tips] O que exatamente est√° acontecendo aqui? 
> Aqui estamos filtrando exatamente a rea√ß√£o a cada tipo de comportamento com base no quanto ele esta disposto a continuar, sendo X o interesse, alem de definir a formula para diminuir ou aumentar a pregui√ßa ao longo do tempo.

## Vis√£o L√≥gica:

As intera√ß√µes e transi√ß√µes de estado dos "Blobs" s√£o definidas por uma s√©rie de condi√ß√µes l√≥gicas que levam em considera√ß√£o os valores de "laziness", "commitment", "interest", al√©m do n√∫mero de dias passados. Essas condi√ß√µes determinam as mudan√ßas no interesse e na pregui√ßa dos "Blobs", modelando seu comportamento ao longo do tempo.

---

Para mais detalhes sobre a implementa√ß√£o e os c√°lculos espec√≠ficos, consulte os documentos de c√≥digo-fonte e as anota√ß√µes no reposit√≥rio.

