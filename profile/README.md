# üëã Bem-vindo ao Visage Track Project!

O Visage Track Project √© dedicado ao Reconhecimento de express√µes faciais em ambientes controlados, gerados proceduralmente utilizando t√©cnicas avan√ßadas de Geometria Anal√≠tica, √Ålgebra Linear e C√°lculo Num√©rico.

**Alunos:** J√°der Louis, Wyllgner Fran√ßa, Nicolas Sales
**Projeto:** Reconhecimento de express√µes faciais em ambientes controlados gerados proceduralmente.  
**Orientador:** Prof. Dr. Lucas Marques

![Perfil do Usu√°rio](https://github.com/visagetrack-project/.github/blob/687927c5ac1b96ad2807e33c2aa88ed99c9fa6e5/profile/unir%201.png)
# Funcionamento do Projeto

O projeto opera da seguinte forma: escolhemos utilizar um ambiente Unity controlado, uma vez que n√£o podemos usar imagens de pessoas reais para treinamento. Assim, criamos seres denominados "blobs" nesse ambiente controlado na Unity, utilizando a f√≥rmula blob para definir suas personalidades e tra√ßos caracter√≠sticos, os quais s√£o gerados aleatoriamente. Isso introduz um grande fator de imprevisibilidade ao projeto.

O projeto √© dividido em v√°rias partes: Web, Comunica√ß√£o, IA (Intelig√™ncia Artificial) e o Ambiente de Controle.

## WEB

Os reposit√≥rios web est√£o dispon√≠veis em:

- **Reposit√≥rio Web:** [vt-web](https://github.com/visagetrack-project/vt-web.git) - Ambiente web desenvolvido em Flutter, incluindo sistema de autentica√ß√£o e banco de dados Firebase.
- **API Prim√°ria:** [vt-api](https://github.com/visagetrack-project/vt-api.git) - Escrita em Go, essa API faz a comunica√ß√£o direta com a web e √© essencial para o funcionamento do projeto.

## Comunica√ß√£o

### API Prim√°ria

A API prim√°ria, cujo reposit√≥rio pode ser encontrado em [vt-api](https://github.com/visagetrack-project/vt-api.git), gerencia as requisi√ß√µes do servidor web e recebe dados processados da API secund√°ria.

### API Secund√°ria

Localizada em [vt-model](https://github.com/visagetrack-project/vt-model), esta API √© respons√°vel pelo processamento das imagens. O arquivo [api_communication.py](https://github.com/visagetrack-project/vt-model/blob/main/api_communication.py) √© utilizado para capturar, transformar os dados e envi√°-los para a API prim√°ria. Importante destacar que `main.py` n√£o chama esse arquivo diretamente; em vez disso, uma API terci√°ria gerencia essa comunica√ß√£o automaticamente, al√©m de gerar gr√°ficos.

### API Terci√°ria

Esta API, escrita em C# e hospedada em um reposit√≥rio privado, √© respons√°vel por gerar as imagens e envi√°-las para serem processadas pela IA. Ela tamb√©m recebe as imagens processadas de volta da API secund√°ria. Al√©m disso, essa API √© respons√°vel por criar um novo ambiente Unity a cada requisi√ß√£o atrav√©s do endpoint `/createNewAmbient{params1}/{params2}/{params3}`, preparando o cen√°rio para as opera√ß√µes das demais APIs.

## IA

### Sobre o MobileNet

O `MobileNet` √© uma arquitetura de Rede Neural Convolucional (CNN) projetada para aplica√ß√µes m√≥veis e embarcadas, destacando-se por sua efici√™ncia computacional e baixo consumo de recursos. Essa fam√≠lia de modelos √© amplamente reconhecida por seu desempenho excepcional em tarefas de vis√£o computacional, como classifica√ß√£o e detec√ß√£o de objetos, oferecendo um equil√≠brio ideal entre precis√£o e velocidade para dispositivos com capacidade de processamento limitada.

### Processo Geral Incorporando o MobileNet

1. **Convers√£o do Modelo para TFLite**: O modelo pr√©-treinado `MobileNet` √© inicialmente convertido para TensorFlow Lite (TFLite), adaptando-o para um uso mais eficiente em dispositivos m√≥veis e de baixa pot√™ncia.

2. **Classifica√ß√£o de Imagens**: Utilizando o modelo convertido, o script aplica o `MobileNet` para classificar objetos em imagens. A fun√ß√£o `tflite_classify_image` processa a imagem de entrada, realiza a infer√™ncia com o modelo TFLite e identifica as principais classes dos objetos presentes na imagem.

3. **Gera√ß√£o de Arquivos XML e CSV**: As informa√ß√µes da classifica√ß√£o s√£o salvas em arquivos XML, que detalham as classifica√ß√µes por imagem, e em um arquivo CSV, que agrega as classes identificadas e suas respectivas probabilidades.

### Funcionamento do MobileNet no Script

- **Infer√™ncia Eficiente**: O script analisa a imagem recebida, utilizando o `MobileNet` para classificar os objetos detectados. Atrav√©s de uma estrutura otimizada e t√©cnicas de processamento avan√ßadas, o modelo oferece rapidez e precis√£o na classifica√ß√£o, mesmo em dispositivos com recursos limitados.

- **P√≥s-processamento e An√°lise**: Ap√≥s a classifica√ß√£o, um p√≥s-processamento √© realizado para extrair as classes dos objetos e suas probabilidades. Essas informa√ß√µes s√£o empregadas para atualizar as imagens com etiquetas indicativas, gerar arquivos XML para cada classifica√ß√£o e compilar um resumo no arquivo CSV.

- **Comunica√ß√£o**: Em seguida, √© recebido um vetor contendo 10 estados, com valores de 0 a 8, que representam as medi√ß√µes realizadas pela IA. Esses dados s√£o processados em [analysis.py](https://github.com/visagetrack-project/vt-model/blob/main/analysis.py) e enviados para a API prim√°ria.

### Aplica√ß√£o do MobileNet

Os resultados da classifica√ß√£o podem ser visualizados na seguinte imagem: ![blobs.jpeg](https://github.com/visagetrack-project/.github/blob/a0ad6ef25561d476ca5be027df0538b9d013afd8/profile/blobs.jpeg)


## Documenta√ß√£o do funcionamento dos 'Blobs'

Para entender o comportamento dos Blobs, √© essencial compreender a f√≥rmula do Gerador Linear Congruente (GLC), que √© a base de tudo isso.

![Documento Blob](https://github.com/visagetrack-project/.github/blob/687927c5ac1b96ad2807e33c2aa88ed99c9fa6e5/profile/WhatsApp%20Image%202024-02-12%20at%2016.09.49.jpeg)

Para entender o comportamento dos Blobs √© essencial entender a formula de GLC (Gerador Linear Congruente), que √© a base de tudo isso
Usando a formula para gerar n√∫meros aleat√≥rios:

$$
X_{n+1} = (aX_n + c) \mod m
$$

- Xn+1‚Äã representa o pr√≥ximo n√∫mero na sequ√™ncia,
- a √© o multiplicador,
- Xn‚Äã √© o n√∫mero atual ou a semente,
- c √© o incremento,
- m √© o m√≥dulo.


Logo definimos as caracter√≠sticas iniciais:

$$
\begin{align*}
\text{Sejam } & min = 0 \text{ e } max = 100. \\
\text{Para cada vari√°vel } & x \in \{ \text{laziness}, \text{commitment}, \text{interest} \}, \\
& x = X_{n+1} = (aX_n + c) \mod m(min,max).
\end{align*}
$$

$$
\begin{align*}
\text{taxaPraDiminuirEmLaziness} &= \frac{\text{commitment}}{2} + \left( \frac{\text{laziness}}{32 - \text{daysCount}} \right) \\\\
\text{commitment} &> 45 =  \\
x &= \left( \frac{5}{1 + \text{laziness}} \right) \cdot \left( \text{interest} \cdot \frac{\text{taxaPraDiminuirEmLaziness}}{100} \right),  \text{estado} = 1 \\ \\
\text{commitment} &< 45 =  \\
x &= \left( \frac{\text{laziness}}{10} \right) \cdot \left( \text{interest} \cdot \frac{\text{taxaPraDiminuirEmLaziness}}{1000} \right), \text{estado} = 0 \\\\
& x > 10,  x = 10 \\
& x < -10,  x = -10 
\end{align*}
$$

> [!tips] O que exatamente est√° acontecendo aqui? 
> Aqui estamos filtrando exatamente a rea√ß√£o a cada tipo de comportamento com base no quanto ele esta disposto a continuar, sendo X o interesse, alem de definir a formula para diminuir ou aumentar a pregui√ßa ao longo do tempo.

## Vis√£o L√≥gica:

As intera√ß√µes e transi√ß√µes de estado dos "Blobs" s√£o definidas por uma s√©rie de condi√ß√µes l√≥gicas que levam em considera√ß√£o os valores de "laziness", "commitment", "interest", al√©m do n√∫mero de dias passados. Essas condi√ß√µes determinam as mudan√ßas no interesse e na pregui√ßa dos "Blobs", modelando seu comportamento ao longo do tempo.

---

Para mais detalhes sobre a implementa√ß√£o e os c√°lculos espec√≠ficos, consulte os documentos de c√≥digo-fonte e as anota√ß√µes no reposit√≥rio.

